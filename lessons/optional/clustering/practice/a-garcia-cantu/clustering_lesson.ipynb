{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://imgur.com/1ZcRyrc.png\" style=\"float: left; margin: 20px; height: 55px\">\n",
    "\n",
    "# Clustering\n",
    "\n",
    "_Author: Sinan Uozdemir (San Francisco)_\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"learning-objectives\"></a>\n",
    "### Learning Objectives\n",
    "- Know the difference between supervised and unsupervised learning.\n",
    "- Format and preprocess data for clustering\n",
    "- Understand and know how to apply k-means clustering.\n",
    "- Understand and know how to apply density-based clustering (DBSCAN).\n",
    "- Define the Silhouette Coefficient and how it relates to clustering.\n",
    "- Evaluate clusters for fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lesson Guide\n",
    "- [Supervised vs. Unsupervised Learning](#supervised-vs-unsupervised)\n",
    "- [Unsupervised Learning](#unsupervised-learning)\n",
    "    - [How could unsupervised learning or clustering be useful?](#userful-unsupervised-learning)\n",
    "\t- [Unsupervised Learning Example: Coin Clustering](#unsupervised-learning-example-coin-clustering)\n",
    "\t- [Common Types of Unsupervised Learning](#common-types-of-unsupervised-learning)\n",
    "\t- [Using Multiple Types of Learning Together](#using-multiple-types-of-learning-together)\n",
    "- [Clustering](#clustering)\n",
    "- [K-Means: Centroid Clustering](#k-means-centroid-clustering)\n",
    "\t- [Visual Demo](#visual-demo)\n",
    "\t- [K-Means Assumptions](#assumptions-are-important-k-means-assumes)\n",
    "- [K-Means Demo](#k-means-demo)\n",
    "\t- [K-Means Clustering](#k-means-clustering)\n",
    "\t- [Repeat With Scaled Data](#repeat-with-scaled-data)\n",
    "- [Clustering Metrics](#clustering-metrics)\n",
    "- [DBSCAN: Density-Based Clustering](#dbscan-density-based-clustering)\n",
    "\t- [Visual Demo](#visual-demo)\n",
    "- [DBSCAN Clustering Demo](#dbscan-clustering-demo)\n",
    "- [Hierarchical Clustering](#hierarchical-clustering)\n",
    "- [Clustering, Classification, and Regression](#clustering-classification-and-regression)\n",
    "- [Comparing Clustering Algorithms](#comparing-clustering-algorithms)\n",
    "- [Lesson Summary](#lesson-summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"supervised-vs-unsupervised\"></a>\n",
    "What's the difference between supervised and unsupervised learning?\n",
    "==\n",
    "\n",
    "**Supervised learning (a.k.a., “predictive modeling”):**\n",
    "Classification and regression\n",
    "\n",
    "- Predicts an outcome based on input data.\n",
    "     - Example: Predicts whether an email is spam or ham.\n",
    "- Attempts to generalize.\n",
    "- Requires past data on the element we want to predict (the target).\n",
    "\n",
    "\n",
    "**Unsupervised learning:**\n",
    "Clustering and dimensionality reduction\n",
    "\n",
    "- Extracts structure from data.\n",
    "    - Example: Segmenting grocery store shoppers into “clusters” that exhibit similar behaviors.\n",
    "- Attempts to represent.\n",
    "- Does not require past data on the element we want to predict."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![supervised-vs-unsupervised](assets/supervised-vs-unsupervised.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"unsupervised-learning\"></a>\n",
    "## Unsupervised Learning\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Supervised learning focuses on finding a relationship between a matrix of features and a response variable. \n",
    "\n",
    "There is typically additional (latent) structure hiding in the feature matrix. For example, some features might be related to each other or even redundant. There also could be groups of observations that seem to be related.\n",
    "\n",
    "Taking advantage of these latent structures allows us to study data without an explicit response in mind and to find better representations for our data to improve predictive performance.\n",
    "\n",
    "**Unsupervised learning** is designed to identify these kinds of structural relationships in our data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **The primary goal of unsupervised learning is \"representation.\"** Unsupervised learning extracts structure from data. For example, you could segment grocery-store shoppers into \"clusters\" of shoppers who exhibit similar behaviors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far, we have primarily studied supervised algorithms: Each observation (row of data) comes with one or more labels -- either categorical variables (classes) or measurements (regression).\n",
    "\n",
    "Unsupervised learning has a different goal: feature discovery.\n",
    "\n",
    "> One common and fundamental example of unsupervised learning is **clustering**. Clustering algorithms are used to find meaningful groups within data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Unsupervised learning is clearly differentiated from supervised learning.** With unsupervised learning:\n",
    "\n",
    "- There's no clear objective.\n",
    "- There's no \"right answer\" (which means it's hard to tell how well you're doing).\n",
    "- There's no response variable — only observations with features.\n",
    "- Labeled data is not required."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"userful-unsupervised-learning\"></a>\n",
    "# How could unsupervised learning or clustering be useful?\n",
    "\n",
    "### Helpful uses for clustering: \n",
    "   - Find items with similar behavior (users, products, voters, etc)\n",
    "   - Market segmentation\n",
    "   - Understand complex systems\n",
    "   - Discover meaningful categories for your data\n",
    "   - Reduce the number of classes by grouping (e.g. bourbons, scotches -> whiskeys)\n",
    "   - Reduce the dimensions of your problem\n",
    "   - Pre-processing! Create labels for supervised learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"unsupervised-learning-example-coin-clustering\"></a>\n",
    "### An Example of Unsupervised Learning: Coin Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Observations: Coins\n",
    "- Features: Size and mass\n",
    "- Response: None (no hand-labeling required!)\n",
    "\n",
    "- Perform unsupervised learning:\n",
    "  - Cluster the coins based on “similarity.”\n",
    "  - You’re done!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./assets/images/unsupervised-coin.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![coin](../../assets/unsupervised-coin.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What would you imagine a plot of US coins to look like? Are these coins likely US coins (pennies, nickels, dimes, and quarters)?\n",
    "\n",
    "**Answer:** ---\n",
    "\n",
    "What conclusions could you make about this group of coins?\n",
    "\n",
    "**Answer:** ---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"common-types-of-unsupervised-learning\"></a>\n",
    "### Common Types of Unsupervised Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Clustering:** Group “similar” data points together.\n",
    "\n",
    "**Dimensionality Reduction:** Reduce the dimensionality of a data set by extracting features that capture most of the variance in the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"using-multiple-types-of-learning-together\"></a>\n",
    "### Using Multiple Types of Learning Together\n",
    "None of these techniques are mutually exclusive, and they can be used in combination for better results. A useful example is **transfer learning** or **ensemble learning**.\n",
    "\n",
    "Imagine you have a 100,000-row data set with no response values. Your job is to create a response with hand-labels and then create an algorithm to predict the response using supervised learning. \n",
    "\n",
    "Unfortunately, you only have time to label 10,000 rows. Does that mean the rest of the data is useless?\n",
    "\n",
    "The extra 90,000 rows are very useful! We can first use unsupervised learning to identify hidden structures such as related features and groups that naturally form in our data. The unsupervised learning algorithms can transform both our unlabeled and labeled data into a form that's easier to predict from.\n",
    "\n",
    "We then use the new transformed data with supervised learning to get the predictions we were looking for."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"clustering\"></a>\n",
    "## Clustering\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're going to cover three major clustering approaches:\n",
    "\n",
    "- **Centroid clustering using k-means:** Looks for the centers of k pre-specified groups.\n",
    "\n",
    "- **Density-based clustering using DBSCAN:** Looks at gaps, or lack thereof, between datapoints.\n",
    "\n",
    "- **Hierarchical clustering using agglomerative clustering:** Forms groups of groups of groups in a hierarchy to determine clusters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### K-Means Clustering\n",
    "\n",
    "Similarly to k-nearest neighbors, this partitions the entire space into regions (Voronoi partitions). In k-means clustering, k refers to the number of clusters. Also, since this is unsupervised learning, the regions are determined by the k-means algorithm instead of being provided by the training data.\n",
    "\n",
    "**Question:** Why might data often appear in centered clusters?\n",
    "\n",
    "![](./assets/images/clustering-centroids.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Density-Based Clustering\n",
    "\n",
    "In DBSCAN (Density-Based Spatial Clustering of Applications with Noise), clusters are created from areas of high density. This can lead to irregularly shaped regions. Also, many parts of space may not belong to any region.\n",
    "\n",
    "**Question:** Why might data often appear in density-based clusters?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./assets/images/density-clusters.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hierarchical Clustering\n",
    "\n",
    "In hierarchical clustering, clusters are composed by joining two smaller clusters together.\n",
    "\n",
    "Below, we see a tree data structure that stores clusters of points:\n",
    "- Each node represents a cluster of one or more data points.\n",
    "- Each leaf represents a single data point.\n",
    "- The root is the cluster containing all data points.\n",
    "- Each parent combines its children's clusters to create a new (larger) cluster.\n",
    "\n",
    "**Question:** When might hierarchical clustering be useful?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./assets/images/hierarchical-clustering.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** How is unsupervised learning different from classification?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** Can you think of real-world clustering applications?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"k-means-centroid-clustering\"></a>\n",
    "## K-Means: Centroid Clustering\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K-means clustering is a popular centroid-based clustering algorithm.\n",
    " \n",
    "In k-means clustering, we find $k$ clusters (where $k$ is user-specified), each distributed around a single point (called a **centroid**, an imaginary \"center point\" or the cluster's \"center of mass\").\n",
    "\n",
    "> **K-means seeks to minimize the sum of squares of each point about its cluster centroid.**\n",
    "\n",
    "If we manage to minimize this, then we claim to have found good clusters.\n",
    "\n",
    "- As a class, try drawing three clusters and data points in which this constraint is met.\n",
    "- Draw another diagram where the constraint is not met.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![clustering-centroids](../../assets/clustering-centroids.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K Means\n",
    "\n",
    "1. Pick a value for k (the number of clusters to create)\n",
    "2. Initialize k 'centroids' (starting points) in your data\n",
    "3. Assign each point to the nearest centroid. These are your clusters.\n",
    "4. Make your clusters better. Move each centroid to the center of its cluster. \n",
    "5. Repeat steps 3-4 until your centroids converge. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Pick a value for k (the number of clusters to create)\n",
    "=="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../../assets/kmeans1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Initialize k 'centroids' (starting points) in your data\n",
    "=="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../../assets/kmeans2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Assign each point to the nearest centroid. These are your clusters.\n",
    "=="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../../assets/kmeans3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Make your clusters better. Move each centroid to the center of its cluster. \n",
    "=="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../../assets/kmeans4.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Make your clusters better. Move each centroid to the center of its cluster. \n",
    "=="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../../assets/kmeans5.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Repeat steps 3-4 until your centroids converge. \n",
    "=="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../../assets/kmeans6.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Repeat steps 3-4 until your centroids converge. \n",
    "=="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../../assets/kmeans7.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Repeat steps 3-4 until your centroids converge. \n",
    "=="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../../assets/kmeans8.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Repeat steps 3-4 until your centroids converge. \n",
    "=="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../../assets/kmeans9.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Repeat steps 3-4 until your centroids converge. \n",
    "=="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../../assets/kmeans10.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-means seeks to minimize the sum of squares of each point about its cluster centroid.\n",
    " \n",
    "Let's see step-by-step how we might write an error function that describes this goal. Luckily, we already have experience with sum of squares, so we'll start there. \n",
    "\n",
    "> Although the final equation might look complex, you can understand it by thinking about it step-by-step and always relating each step back to the original goal. Do not let any fear of math get in your way!\n",
    "\n",
    "Keep in mind that unlike a lot of what you do in math, the math we're about to see is not a \"law\" and it is not \"derived\" from any equation. It was arrived at only because someone thought the goal metric above would be a useful description of one type of cluster. As we showed earlier, many other definitions of \"clusters\" are equally valid.\n",
    "\n",
    "#### Step One: Definitions\n",
    "\n",
    "Let's step through a few definitions we'll need to formalize the statement. Note that every data point must belong to exactly one cluster.\n",
    "\n",
    "- $S_i$ is the set of points in the $i$th cluster. For example:\n",
    "    - $S_1 = \\{(1, 1), (2, 1), (0, 1)\\}$.\n",
    "    - $S_2 = \\{(10, 10), (12, 10)\\}$.\n",
    "\n",
    "\n",
    "- $x$ is an arbitrary point. For example:\n",
    "    - $x = (2, 1)$.\n",
    "    - Note that $x \\in S_1$. This reads: \"$x$ belongs to $S_1$\" or just \"$x$ in $S_1$.\"\n",
    "    \n",
    "\n",
    "- $\\mu_i$ is the centroid (\"center point\") of all points in $S_i$. For example:\n",
    "    - $\\mu_1 = (\\frac{1+2+0}{3}, \\frac{1+1+1}{3}) = (1, 1)$.\n",
    "    - $\\mu_2 = (\\frac{10+12}{2}, \\frac{10+10}{2}) = (11, 10)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step Two: Error of one cluster\n",
    "\n",
    "We need to measure the \"tightness\" of each cluster -- the closer its points are to the centroid, the better. So, we'll measure how far away each point is from the centroid. Further, we'll square each distance to particularly penalize far away points.\n",
    "\n",
    "So, the sum of the distances of each point $x$ to $\\mu$ is just:\n",
    "\n",
    "$$E_i(S) = {\\sum_{x \\in S} {\\|x - \\mu\\|^2}}$$\n",
    "\n",
    "> This is read: \"The sum of the square distances of each point in S to the centroid of S.\"\n",
    "\n",
    "**Question:** How does this relate to the goal statement?\n",
    "\n",
    "**Answer:** ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step Three: Sum of all cluster errors\n",
    "\n",
    "Now, let's find this sum for each cluster. If we sum these sums together, that is the total error for all $k$ clusters:\n",
    "\n",
    "$$E_{total}(S_1, ..., S_k) = \\sum_{i=1}^k E_i(S_i)$$\n",
    "\n",
    "$$= \\sum_{i=1}^k {\\sum_{x \\in S} {\\|x - \\mu\\|^2}}$$\n",
    "\n",
    "**Question:** How does this relate to the goal statement?\n",
    "\n",
    "**Answer:** ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step Four: Find the clusters that minimize total error\n",
    "\n",
    "Precisely, find $k$ partitions $S_1, …, S_k$ of the data with centroids $\\mu_1, …, \\mu_k$ that minimize $E_{total}$. In other words:\n",
    "\n",
    "$$\\text{argmin}_{S_1, …, S_k} \\sum_{i=1}^k {\\sum_{x \\in S_i} {\\|x - \\mu_i\\|^2}}$$\n",
    "\n",
    "> $\\text{argmin}_{S_1, …, S_k}\\ f(S_1, ..., S_k)$: Find the values of $S_1, ..., S_k$ that minimize $f(S_1, ..., S_k)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a computationally difficult problem to solve, so we often rely on heuristics.\n",
    "\n",
    "The \"standard\" heuristic is called **Lloyd’s Algorithm**:\n",
    "1. Start with $k$ initial (random) points* (we'll call these \"centroids\").\n",
    "2. Assign each datapoint to a cluster by finding its \"closest\" centroid (e.g. using Euclidean distance).\n",
    "3. Calculate new centroids based on the datapoints assigned to each cluster.\n",
    "4. Repeat 2-4 until clusters do not change.\n",
    "\n",
    "\\* There are a number of techniques for choosing initial points. For example, see the `k-means++` technique."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"visual-demo\"></a>\n",
    "### Visual Demo\n",
    "\n",
    "[Click through](https://www.naftaliharris.com/blog/visualizing-k-means-clustering/) for a demo of k-means clustering in action.\n",
    "\n",
    "![voronoi](../../assets/voronoi.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"assumptions-are-important-k-means-assumes\"></a>\n",
    "### K-Means Assumptions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K-means assumes:\n",
    "\n",
    "- k is the correct number of clusters.\n",
    "- The data is isotropically distributed (circular/spherical distribution).\n",
    "- The variance is the same for each variable.\n",
    "- Clusters are roughly the same size.\n",
    "\n",
    "View these resources to see counterexamples/cases where assumptions are not met:\n",
    "- [Variance Explained](http://varianceexplained.org/r/kmeans-free-lunch/)\n",
    "- [Scikit-Learn](http://scikit-learn.org/stable/auto_examples/cluster/plot_kmeans_assumptions.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How do we choose k?\n",
    "\n",
    "Finding the correct k to use for k-means clustering is not a simple task.\n",
    "\n",
    "We do not have a ground-truth we can use, so there isn't necessarily a \"correct\" number of clusters. However, we can find metrics that try to quantify the quality of our groupings.\n",
    "\n",
    "Our application is also an important consideration. For example, during customer segmentation we want clusters that are large enough to be targetable by the marketing team. In that case, even if the most natural-looking clusters are small, we may try to group several of them together so that it makes financial sense to target those groups.\n",
    "\n",
    "**Common approaches include:**\n",
    "- Figuring out the correct number of clusters from previous experience.\n",
    "- Using the elbow method to find a number of clusters that no longer seems to improve a clustering metric by a noticeable degree.\n",
    "  - The silhouette coefficient is a commonly used measure.\n",
    "  - For an example, check out this [silhouette analysis](http://scikit-learn.org/stable/auto_examples/cluster/plot_kmeans_silhouette_analysis.html) documentation on sklearn.\n",
    "  - If we're using clustering to improve performance on a supervised learning problem, then we can use our usual methods to test predictions.\n",
    "  \n",
    "**It's tempting to \"tune\" k as we have in supervised learning:**\n",
    "  - If we are working on a supervised learning problem, then this is possible.\n",
    "  - If we are using clustering to explore our data, then tuning is of little benefit since we do not know precisely what we are looking for."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"k-means-demo\"></a>\n",
    "## K-Means Demo\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>calories</th>\n",
       "      <th>sodium</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>cost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Budweiser</td>\n",
       "      <td>144</td>\n",
       "      <td>15</td>\n",
       "      <td>4.7</td>\n",
       "      <td>0.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Schlitz</td>\n",
       "      <td>151</td>\n",
       "      <td>19</td>\n",
       "      <td>4.9</td>\n",
       "      <td>0.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lowenbrau</td>\n",
       "      <td>157</td>\n",
       "      <td>15</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Kronenbourg</td>\n",
       "      <td>170</td>\n",
       "      <td>7</td>\n",
       "      <td>5.2</td>\n",
       "      <td>0.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Heineken</td>\n",
       "      <td>152</td>\n",
       "      <td>11</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.77</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          name  calories  sodium  alcohol  cost\n",
       "0    Budweiser       144      15      4.7  0.43\n",
       "1      Schlitz       151      19      4.9  0.43\n",
       "2    Lowenbrau       157      15      0.9  0.48\n",
       "3  Kronenbourg       170       7      5.2  0.73\n",
       "4     Heineken       152      11      5.0  0.77"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Beer data set\n",
    "import pandas as pd\n",
    "url = '../../data/beer.txt'\n",
    "beer = pd.read_csv(url, sep=' ')\n",
    "beer.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How would you cluster these beers?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>calories</th>\n",
       "      <th>sodium</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>cost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>144</td>\n",
       "      <td>15</td>\n",
       "      <td>4.7</td>\n",
       "      <td>0.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>151</td>\n",
       "      <td>19</td>\n",
       "      <td>4.9</td>\n",
       "      <td>0.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>157</td>\n",
       "      <td>15</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>170</td>\n",
       "      <td>7</td>\n",
       "      <td>5.2</td>\n",
       "      <td>0.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>152</td>\n",
       "      <td>11</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.77</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   calories  sodium  alcohol  cost\n",
       "0       144      15      4.7  0.43\n",
       "1       151      19      4.9  0.43\n",
       "2       157      15      0.9  0.48\n",
       "3       170       7      5.2  0.73\n",
       "4       152      11      5.0  0.77"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define X.\n",
    "X = beer.drop('name', axis=1)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What happened to Y?\n",
    "\n",
    "- Y represents the labels in supervised learning. Because clustering is unsupervised, each input point has no target label. So, there is no Y needed for k-means."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"k-means-clustering\"></a>\n",
    "### K-Means Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### K-means with three clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KMeans(algorithm='auto', copy_x=True, init='k-means++', max_iter=300,\n",
       "    n_clusters=3, n_init=10, n_jobs=None, precompute_distances='auto',\n",
       "    random_state=1, tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pandas.plotting import scatter_matrix\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "## Instantiate\n",
    "km = KMeans(n_clusters=3, random_state=1)\n",
    "\n",
    "## Where is test train split??\n",
    "\n",
    "## Fit\n",
    "km.fit(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Review the cluster labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 2, 0, 0, 2, 1], dtype=int32)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "km.labels_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save the cluster labels and sort by cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>calories</th>\n",
       "      <th>sodium</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>cost</th>\n",
       "      <th>cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Budweiser</td>\n",
       "      <td>144</td>\n",
       "      <td>15</td>\n",
       "      <td>4.7</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Schlitz</td>\n",
       "      <td>151</td>\n",
       "      <td>19</td>\n",
       "      <td>4.9</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lowenbrau</td>\n",
       "      <td>157</td>\n",
       "      <td>15</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Kronenbourg</td>\n",
       "      <td>170</td>\n",
       "      <td>7</td>\n",
       "      <td>5.2</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Heineken</td>\n",
       "      <td>152</td>\n",
       "      <td>11</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          name  calories  sodium  alcohol  cost  cluster\n",
       "0    Budweiser       144      15      4.7  0.43        0\n",
       "1      Schlitz       151      19      4.9  0.43        0\n",
       "2    Lowenbrau       157      15      0.9  0.48        0\n",
       "3  Kronenbourg       170       7      5.2  0.73        0\n",
       "4     Heineken       152      11      5.0  0.77        0"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beer['cluster'] = km.labels_\n",
    "beer.sort_values('cluster').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What do the clusters seem to be based on? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Review the cluster centers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 150.        ,   17.        ,    4.52142857,    0.52071429],\n",
       "       [ 102.75      ,   10.        ,    4.075     ,    0.44      ],\n",
       "       [  70.        ,   10.5       ,    2.6       ,    0.42      ]])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "km.cluster_centers_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate the mean of each feature for each cluster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "beer.groupby('cluster').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save the `DataFrame` of cluster centers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>calories</th>\n",
       "      <th>sodium</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>cost</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cluster</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>150.00</td>\n",
       "      <td>17.0</td>\n",
       "      <td>4.521429</td>\n",
       "      <td>0.520714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>102.75</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4.075000</td>\n",
       "      <td>0.440000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>70.00</td>\n",
       "      <td>10.5</td>\n",
       "      <td>2.600000</td>\n",
       "      <td>0.420000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         calories  sodium   alcohol      cost\n",
       "cluster                                      \n",
       "0          150.00    17.0  4.521429  0.520714\n",
       "1          102.75    10.0  4.075000  0.440000\n",
       "2           70.00    10.5  2.600000  0.420000"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "centers = beer.groupby('cluster').mean()\n",
    "centers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Allow plots to appear in the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['font.size'] = 14"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a \"colors\" array for plotting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "colors = np.array(['red', 'green', 'blue', 'yellow'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scatter plot of calories versus alcohol, colored by cluster (0=red, 1=green, 2=blue)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(beer.calories, beer.alcohol, c=colors[beer.cluster], s=50);\n",
    "\n",
    "# Cluster centers, marked by \"+\"\n",
    "plt.scatter(centers.calories, centers.alcohol, linewidths=3, marker='+', s=300, c='black');\n",
    "\n",
    "# Add labels.\n",
    "plt.xlabel('calories')\n",
    "plt.ylabel('alcohol')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scatter plot matrix (0=red, 1=green, 2=blue)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter_matrix(X, c=colors[beer.cluster], figsize=(10,10), s=100);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"repeat-with-scaled-data\"></a>\n",
    "### Repeat With Scaled Data\n",
    "\n",
    "Unscaled features cause most algorithms to put too much weight onto one feature. We can scale our data to make sure k-means accounts for all features.\n",
    "\n",
    "Remember that k-means is looking for isotropic groups, meaning that they disperse from the center in all directions evenly. \n",
    "\n",
    "There is more than one choice of scaling method (min/max, z-score, log, etc.), but the best choice is the one that makes your clusters isotropic."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Center and scale the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/base.py:464: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### K-means with three clusters on scaled data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KMeans(algorithm='auto', copy_x=True, init='k-means++', max_iter=300,\n",
       "    n_clusters=3, n_init=10, n_jobs=None, precompute_distances='auto',\n",
       "    random_state=1, tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "km = KMeans(n_clusters=3, random_state=1)\n",
    "km.fit(X_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.38791334,  0.00779468,  0.43380786, -0.45682969],\n",
       "       [ 0.6250656 ,  0.63136906,  0.62241997, -0.45682969],\n",
       "       [ 0.82833896,  0.00779468, -3.14982226, -0.10269815],\n",
       "       [ 1.26876459, -1.23935408,  0.90533814,  1.66795955],\n",
       "       [ 0.65894449, -0.6157797 ,  0.71672602,  1.95126478],\n",
       "       [ 0.42179223,  1.25494344,  0.3395018 , -1.5192243 ],\n",
       "       [ 1.43815906,  1.41083704,  1.1882563 , -0.66930861],\n",
       "       [ 0.55730781,  1.87851782,  0.43380786, -0.52765599],\n",
       "       [-1.1366369 , -0.7716733 ,  0.05658363, -0.45682969],\n",
       "       [-0.66233238, -1.08346049, -0.5092527 , -0.66930861],\n",
       "       [ 0.25239776,  0.47547547,  0.3395018 , -0.38600338],\n",
       "       [-1.03500022,  0.00779468, -0.13202848, -0.24435076],\n",
       "       [ 0.08300329, -0.6157797 , -0.03772242,  0.03895447],\n",
       "       [ 0.59118671,  0.63136906,  0.43380786,  1.88043848],\n",
       "       [ 0.55730781, -1.39524768,  0.71672602,  2.0929174 ],\n",
       "       [-2.18688263,  0.00779468, -1.82953748, -0.81096123],\n",
       "       [ 0.21851887,  0.63136906,  0.15088969, -0.45682969],\n",
       "       [ 0.38791334,  1.41083704,  0.62241997, -0.45682969],\n",
       "       [-2.05136705, -1.39524768, -1.26370115, -0.24435076],\n",
       "       [-1.20439469, -1.23935408, -0.03772242, -0.17352445]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save the cluster labels and sort by cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>calories</th>\n",
       "      <th>sodium</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>cost</th>\n",
       "      <th>cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Budweiser</td>\n",
       "      <td>144</td>\n",
       "      <td>15</td>\n",
       "      <td>4.7</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Schlitz</td>\n",
       "      <td>151</td>\n",
       "      <td>19</td>\n",
       "      <td>4.9</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Heilemans_Old_Style</td>\n",
       "      <td>144</td>\n",
       "      <td>24</td>\n",
       "      <td>4.9</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Hamms</td>\n",
       "      <td>139</td>\n",
       "      <td>19</td>\n",
       "      <td>4.4</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Old_Milwaukee</td>\n",
       "      <td>145</td>\n",
       "      <td>23</td>\n",
       "      <td>4.6</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   name  calories  sodium  alcohol  cost  cluster\n",
       "0             Budweiser       144      15      4.7  0.43        0\n",
       "1               Schlitz       151      19      4.9  0.43        0\n",
       "17  Heilemans_Old_Style       144      24      4.9  0.43        0\n",
       "16                Hamms       139      19      4.4  0.43        0\n",
       "5         Old_Milwaukee       145      23      4.6  0.28        0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beer['cluster'] = km.labels_\n",
    "beer.sort_values('cluster').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What are the \"characteristics\" of each cluster?\n",
    "\n",
    "**Answer: One possible interpretation:**\n",
    "\n",
    "- Cluster 0: Regular beers\n",
    "- Cluster 1: Light beers (lower calorie, lower alcohol)\n",
    "- Cluster 2: Expensive (high cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Review the cluster centers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>calories</th>\n",
       "      <th>sodium</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>cost</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cluster</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>148.375</td>\n",
       "      <td>21.125</td>\n",
       "      <td>4.7875</td>\n",
       "      <td>0.4075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>105.375</td>\n",
       "      <td>10.875</td>\n",
       "      <td>3.3250</td>\n",
       "      <td>0.4475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>155.250</td>\n",
       "      <td>10.750</td>\n",
       "      <td>4.9750</td>\n",
       "      <td>0.7625</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         calories  sodium  alcohol    cost\n",
       "cluster                                   \n",
       "0         148.375  21.125   4.7875  0.4075\n",
       "1         105.375  10.875   3.3250  0.4475\n",
       "2         155.250  10.750   4.9750  0.7625"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beer.groupby('cluster').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scatter plot matrix of new cluster assignments (0=red, 1=green, 2=blue)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter_matrix(X, c=colors[beer.cluster], figsize=(10,10), s=100);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Do you notice any cluster assignments that seem a bit odd? How might we explain those?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"clustering-metrics\"></a>\n",
    "Metrics for assessing your clusters\n",
    "==\n",
    "---\n",
    "\n",
    "As usual, we need a metric to evaluate model fit.\n",
    " \n",
    "For clustering, we can us a **Inertia** or a **Silhouette Score**. There are many other approaches, but these are a good place to start. Keep in mind that \"good fit\" for clustering is often arbitrary. For example, scoring isometry might not apply if most clusters are naturally arbitrary shapes. \n",
    "\n",
    "- **Inertia**\n",
    "- **Silhouette Score**\n",
    "\n",
    "\n",
    "Practice using with iris data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iris-versicolor    50\n",
      "Iris-setosa        50\n",
      "Iris-virginica     50\n",
      "Name: Name, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SepalLength</th>\n",
       "      <th>SepalWidth</th>\n",
       "      <th>PetalLength</th>\n",
       "      <th>PetalWidth</th>\n",
       "      <th>Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SepalLength  SepalWidth  PetalLength  PetalWidth         Name\n",
       "0          5.1         3.5          1.4         0.2  Iris-setosa\n",
       "1          4.9         3.0          1.4         0.2  Iris-setosa\n",
       "2          4.7         3.2          1.3         0.2  Iris-setosa\n",
       "3          4.6         3.1          1.5         0.2  Iris-setosa\n",
       "4          5.0         3.6          1.4         0.2  Iris-setosa"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import cluster, datasets, preprocessing, metrics\n",
    "\n",
    "# Check out the dataset and our target values\n",
    "df = pd.read_csv(\"../../data/iris.csv\")\n",
    "cols = df.columns[:-1]\n",
    "print(df['Name'].value_counts())\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inertia\n",
    "==\n",
    "\n",
    "The K-means algorithm aims to choose centroids that minimise the inertia, or within-cluster sum of squared criterion:\n",
    "\n",
    "\n",
    "![inertia](../../assets/inertia.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inertia, or the within-cluster sum of squares criterion, can be recognized as a measure of how internally coherent clusters are. It suffers from various drawbacks:\n",
    "\n",
    "- Inertia makes the assumption that clusters are convex and isotropic (not varying in magnitude according to the direction of measurement), which is not always the case. \n",
    "    - It responds poorly to elongated clusters, or manifolds with irregular shapes.\n",
    "- Inertia is not a normalized metric: \n",
    "    - We just know that lower values are better and zero is optimal. But in very high-dimensional spaces, Euclidean distances tend to become inflated (this is an instance of the so-called “curse of dimensionality”). \n",
    "    - Running a dimensionality reduction algorithm such as PCA prior to k-means clustering can alleviate this problem and speed up the computations.\n",
    "    \n",
    "**High Level Summary of Inertia:**\n",
    "- Sum of squared errors for each cluster\n",
    "- Ranges from 0 to very high values\n",
    "- Low inertia = dense clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KMeans(algorithm='auto', copy_x=True, init='k-means++', max_iter=300,\n",
       "    n_clusters=3, n_init=10, n_jobs=1, precompute_distances='auto',\n",
       "    random_state=None, tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_scaled = preprocessing.MinMaxScaler().fit_transform(df[cols])\n",
    "k = 3\n",
    "kmeans = cluster.KMeans(n_clusters=k)\n",
    "kmeans.fit(X_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 0 2 0 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 0 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 2 0 0 0 0 2 0 0 0 0\n",
      " 0 0 2 0 0 0 0 0 2 0 2 0 2 0 0 2 2 0 0 0 0 0 2 2 0 0 0 2 0 0 0 2 0 0 0 2 0\n",
      " 0 2]\n"
     ]
    }
   ],
   "source": [
    "labels = kmeans.labels_\n",
    "centroids = kmeans.cluster_centers_\n",
    "inertia = kmeans.inertia_\n",
    "\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.70726496  0.4508547   0.79704476  0.82478632]\n",
      " [ 0.19611111  0.59083333  0.07864407  0.06      ]\n",
      " [ 0.44125683  0.30737705  0.57571548  0.54918033]]\n"
     ]
    }
   ],
   "source": [
    "print(centroids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.99811400483\n"
     ]
    }
   ],
   "source": [
    "print(inertia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    When k=2 the inertia is:12.1436882816\n",
      "    \n",
      "\n",
      "    When k=3 the inertia is:6.99811400483\n",
      "    \n",
      "\n",
      "    When k=4 the inertia is:5.53909811221\n",
      "    \n",
      "\n",
      "    When k=5 the inertia is:4.57118050876\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "for k in range(2, 6):\n",
    "    X_scaled = preprocessing.MinMaxScaler().fit_transform(df[cols])\n",
    "    kmeans = cluster.KMeans(n_clusters=k)\n",
    "    kmeans.fit(X_scaled)\n",
    "    labels = kmeans.labels_\n",
    "    centroids = kmeans.cluster_centers_\n",
    "    inertia = kmeans.inertia_\n",
    "    \n",
    "    print(\"\"\"\n",
    "    When k={} the inertia is:{}\n",
    "    \"\"\".format(k, inertia))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Silhouette Score\n",
    "==\n",
    "\n",
    "\n",
    "The Silhouette Coefficient gives a score for each sample individually. At a high level, it compares the point's cohesion to its cluster against its separation from the nearest other cluster. Ideally, you want the point to be very nearby other points in its own cluster and very far points in the nearest other cluster.\n",
    "\n",
    "Here is how the Silhouette Coefficient is measured. Keep in mind how this math definition compares to our high-level idea of a sample's cohesion vs. separation:\n",
    "\n",
    "$$\\frac {b - a} {max(a,b)}$$\n",
    "\n",
    "- $a$ is the mean distance between a sample and all other points in the cluster.\n",
    "\n",
    "- $b$ is the mean distance between a sample and all other points in the nearest cluster.\n",
    "\n",
    "The coefficient ranges between 1 and -1. The larger the coefficient, the better the clustering.\n",
    "\n",
    "To get a score for all clusters rather than for a particular point, we average over all points to judge the cluster algorithm.\n",
    "\n",
    "The Silhouette Coefficient is generally higher for convex clusters than other concepts of clusters, such as density based clusters like those obtained through DBSCAN\n",
    "\n",
    "\n",
    "**Using Sklearn**\n",
    "This function returns the mean Silhouette Coefficient over all samples. To obtain the values for each sample, use silhouette_samples.\n",
    "\n",
    "The best value is 1 and the worst value is -1. Values near 0 indicate overlapping clusters. Negative values generally indicate that a sample has been assigned to the wrong cluster, as a different cluster is more similar.\n",
    "\n",
    "**High Level Summary of Silhouette Score:**\n",
    "- Measure of how far apart clusters are\n",
    "- Ranges from -1 to 1\n",
    "- High silhouette Score = clusters are well separated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    When k=2 the silhousette score is:0.629467556191\n",
      "    \n",
      "\n",
      "    When k=3 the silhousette score is:0.504318854915\n",
      "    \n",
      "\n",
      "    When k=4 the silhousette score is:0.444627330065\n",
      "    \n",
      "\n",
      "    When k=5 the silhousette score is:0.355383152674\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "for k in range(2, 6):\n",
    "    X_scaled = preprocessing.MinMaxScaler().fit_transform(df[cols])\n",
    "    kmeans = cluster.KMeans(n_clusters=k)\n",
    "    kmeans.fit(X_scaled)\n",
    "    labels = kmeans.labels_\n",
    "    \n",
    "    score = metrics.silhouette_score(X_scaled, labels, metric='euclidean')\n",
    "    \n",
    "    print(\"\"\"\n",
    "    When k={} the silhousette score is:{}\n",
    "    \"\"\".format(k, score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"dbscan-density-based-clustering\"></a>\n",
    "## DBSCAN: Density-Based Clustering\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./assets/images/dbscan.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DBSCAN: Density-Based Spatial Clustering of Applications With Noise (1996)**\n",
    "\n",
    "The main idea of DBSCAN is to group together closely packed points by identifying:\n",
    "- Core points\n",
    "- Reachable points\n",
    "- Outliers (not reachable)\n",
    "\n",
    "**Its two parameters are:**\n",
    "- `min_samples`: At least this many points are required inside a neighborhood to form a dense cluster.\n",
    "- `eps`: epsion. This is the radius of a neighborhood.\n",
    "\n",
    "**How does it work?** \n",
    "\n",
    "1. Choose a random unvisited data point.\n",
    "2. Find all points in its neighborhood (i.e. at most `eps` units away). Then:\n",
    "    - **If there are at least `min_samples` points in its neighborhood:** Add all points in the neighborhood to the current cluster. Mark them as unvisited if they have not been visited.\n",
    "    - **Otherwise:** Mark the current point as visited. If the point is not part of a cluster, label the point as noise and go to Step 1.\n",
    "3. If another point in the current cluster is unvisited, choose another point in the cluster and go to Step 2. Otherwise, start a new cluster and go to Step 1.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example of finding clusters\n",
    "![dbscan](../../assets/dbscan.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example of found clusters\n",
    "![density-clusters](../../assets/density-clusters.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"visual-demo\"></a>\n",
    "### Visual Demo\n",
    "\n",
    "[Click through](https://www.naftaliharris.com/blog/visualizing-dbscan-clustering/) for a demo of DBSCAN in action."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DBSCAN advantages**:\n",
    "- Can find arbitrarily shaped clusters.\n",
    "- Don’t have to specify number of clusters.\n",
    "- Excludes outliers automatically.\n",
    "\n",
    "**DBSCAN disadvantages**:\n",
    "- Doesn’t work well when clusters are of varying densities.\n",
    "- Hard to choose parameters that work for all clusters.\n",
    "- Can be hard to choose correct parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How does DBSCAN differ from k-means?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"dbscan-clustering-demo\"></a>\n",
    "## DBSCAN Clustering Demo\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DBSCAN with eps=1 and min_samples=3.\n",
    "\n",
    "Default is `eps=0.5`, `min_samples=5`\n",
    "\n",
    "\n",
    "---\n",
    "**Parameters:**\n",
    "\n",
    "```\n",
    "eps : float, optional\n",
    "The maximum distance between two samples for them to be considered as in the same neighborhood.\n",
    "\n",
    "min_samples : int, optional\n",
    "The number of samples (or total weight) in a neighborhood for a point to be considered as a core point. This includes the point itself.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = '../../data/beer.txt'\n",
    "beer = pd.read_csv(url, sep=' ')\n",
    "X = beer.drop('name', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/base.py:464: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DBSCAN(algorithm='auto', eps=1, leaf_size=30, metric='euclidean',\n",
       "    metric_params=None, min_samples=3, n_jobs=None, p=None)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Scale data\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "## Instantiate\n",
    "db = DBSCAN(eps=1, min_samples=3)\n",
    "\n",
    "## Fit\n",
    "db.fit(X_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Review the cluster labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  0, -1,  1,  1, -1, -1,  0,  2,  2,  0,  2,  0, -1,  1, -1,  0,\n",
       "        0, -1,  2])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.labels_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save the cluster labels and sort by cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>calories</th>\n",
       "      <th>sodium</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>cost</th>\n",
       "      <th>cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lowenbrau</td>\n",
       "      <td>157</td>\n",
       "      <td>15</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.48</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Old_Milwaukee</td>\n",
       "      <td>145</td>\n",
       "      <td>23</td>\n",
       "      <td>4.6</td>\n",
       "      <td>0.28</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Augsberger</td>\n",
       "      <td>175</td>\n",
       "      <td>24</td>\n",
       "      <td>5.5</td>\n",
       "      <td>0.40</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Olympia_Goled_Light</td>\n",
       "      <td>72</td>\n",
       "      <td>6</td>\n",
       "      <td>2.9</td>\n",
       "      <td>0.46</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Becks</td>\n",
       "      <td>150</td>\n",
       "      <td>19</td>\n",
       "      <td>4.7</td>\n",
       "      <td>0.76</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   name  calories  sodium  alcohol  cost  cluster\n",
       "2             Lowenbrau       157      15      0.9  0.48       -1\n",
       "5         Old_Milwaukee       145      23      4.6  0.28       -1\n",
       "6            Augsberger       175      24      5.5  0.40       -1\n",
       "18  Olympia_Goled_Light        72       6      2.9  0.46       -1\n",
       "13                Becks       150      19      4.7  0.76       -1"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beer['cluster'] = db.labels_\n",
    "beer.sort_values('cluster').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Review the cluster centers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>calories</th>\n",
       "      <th>sodium</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>cost</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cluster</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>-1</th>\n",
       "      <td>127.833333</td>\n",
       "      <td>17.0</td>\n",
       "      <td>3.483333</td>\n",
       "      <td>0.460000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>143.142857</td>\n",
       "      <td>19.0</td>\n",
       "      <td>4.628571</td>\n",
       "      <td>0.440000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>157.000000</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.066667</td>\n",
       "      <td>0.763333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>102.750000</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4.075000</td>\n",
       "      <td>0.440000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           calories  sodium   alcohol      cost\n",
       "cluster                                        \n",
       "-1       127.833333    17.0  3.483333  0.460000\n",
       " 0       143.142857    19.0  4.628571  0.440000\n",
       " 1       157.000000     8.0  5.066667  0.763333\n",
       " 2       102.750000    10.0  4.075000  0.440000"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beer.groupby('cluster').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scatter plot matrix of DBSCAN cluster assignments (0=red, 1=green, 2=blue, -1=yellow)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter_matrix(X, c=colors[beer.cluster], figsize=(10,10), s=100);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"hierarchical-clustering\"></a>\n",
    "## Hierarchical Clustering\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hierarchical clustering, like k-means clustering, is another common form of clustering analysis. With this type of clustering we seek to do exactly what the name suggests:\n",
    "\n",
    "- Build hierarchies of clusters.\n",
    "- Connect the clusters in the hierarchy with links.\n",
    "\n",
    "Once the links are determined, we can display them in what is called a dendrogram — a graph that displays all of these links in their hierarchical structure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 1\n",
    "![hierarchical-clustering](../../assets/hierarchical-clustering.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 2\n",
    "\n",
    "![hierarchical-clustering-diagram](../../assets/hierarchical-clustering-diagram.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**As we described earlier:**\n",
    "\n",
    "- Each node represents a cluster of one or more data points.\n",
    "- Each leaf represents a single data point.\n",
    "- The root is the cluster containing all data points.\n",
    "- Each parent combines its children's clusters to create a new (larger) cluster.\n",
    "\n",
    "**A simple algorithm we could use to generate this tree:**\n",
    "\n",
    "1. Create a cluster for each point, containing only that point. (Create all leaf nodes.)\n",
    "2. Choose the two clusters with centroids closest to each other.\n",
    "    - Combine the two clusters into a new cluster that replaces the two individual clusters. (Create a new parent node.)\n",
    "3. Repeat Step 2 until only one cluster remains.\n",
    "\n",
    "As a class, try this algorithm on the board. Draw the graph alongside clustering the data points.\n",
    "\n",
    "Essentially we form groups of groups of groups.\n",
    "\n",
    "![](../../assets/hierarchical-clustering.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example Sklearn**\n",
    "\n",
    "Use Sklearn's AgglomerativeClustering for Hierarchical clustering.\n",
    "\n",
    "**Parameters:**\n",
    "```\n",
    "The AgglomerativeClustering object performs a hierarchical clustering using a bottom up approach: each observation starts in its own cluster, and clusters are successively merged together. The linkage criteria determines the metric used for the merge strategy:\n",
    "\n",
    "- **Ward** minimizes the sum of squared differences within all clusters. It is a variance-minimizing approach and in this sense is similar to the k-means objective function but tackled with an agglomerative hierarchical approach.\n",
    "- **Maximum** or **complete linkage** minimizes the maximum distance between observations of pairs of clusters.\n",
    "- **Average linkage** minimizes the average of the distances between all observations of pairs of clusters.\n",
    "- **Single linkage** minimizes the distance between the closest observations of pairs of clusters.\n",
    "\n",
    "AgglomerativeClustering can also scale to large number of samples when it is used jointly with a connectivity matrix, but is computationally expensive when no connectivity constraints are added between samples: it considers at each step all the possible merges.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from scipy.cluster import hierarchy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iris-versicolor    50\n",
      "Iris-setosa        50\n",
      "Iris-virginica     50\n",
      "Name: Name, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SepalLength</th>\n",
       "      <th>SepalWidth</th>\n",
       "      <th>PetalLength</th>\n",
       "      <th>PetalWidth</th>\n",
       "      <th>Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SepalLength  SepalWidth  PetalLength  PetalWidth         Name\n",
       "0          5.1         3.5          1.4         0.2  Iris-setosa\n",
       "1          4.9         3.0          1.4         0.2  Iris-setosa\n",
       "2          4.7         3.2          1.3         0.2  Iris-setosa\n",
       "3          4.6         3.1          1.5         0.2  Iris-setosa\n",
       "4          5.0         3.6          1.4         0.2  Iris-setosa"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check out the dataset and our target values\n",
    "df = pd.read_csv(\"../../data/iris.csv\")\n",
    "cols = df.columns[:-1]\n",
    "print(df['Name'].value_counts())\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SepalLength</th>\n",
       "      <th>SepalWidth</th>\n",
       "      <th>PetalLength</th>\n",
       "      <th>PetalWidth</th>\n",
       "      <th>Name</th>\n",
       "      <th>cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>6.4</td>\n",
       "      <td>2.9</td>\n",
       "      <td>4.3</td>\n",
       "      <td>1.3</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>6.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.6</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>5.4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>6.0</td>\n",
       "      <td>2.7</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.6</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>5.8</td>\n",
       "      <td>2.7</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1.2</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    SepalLength  SepalWidth  PetalLength  PetalWidth             Name  cluster\n",
       "74          6.4         2.9          4.3         1.3  Iris-versicolor        0\n",
       "85          6.0         3.4          4.5         1.6  Iris-versicolor        0\n",
       "84          5.4         3.0          4.5         1.5  Iris-versicolor        0\n",
       "83          6.0         2.7          5.1         1.6  Iris-versicolor        0\n",
       "82          5.8         2.7          3.9         1.2  Iris-versicolor        0"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df[cols]\n",
    "\n",
    "## Scale data\n",
    "scaler = StandardScaler()\n",
    "X_scaled = preprocessing.MinMaxScaler().fit_transform(X)\n",
    "\n",
    "## Instantiate\n",
    "agg = AgglomerativeClustering(n_clusters=3)\n",
    "\n",
    "## Fit\n",
    "agg.fit(X_scaled)\n",
    "\n",
    "## Get the labels\n",
    "labels = agg.labels_\n",
    "\n",
    "# Save the cluster labels and sort by cluster.\n",
    "df['cluster'] = agg.labels_\n",
    "df.sort_values('cluster').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter plot matrix of hierarchical cluster assignments\n",
    "scatter_matrix(X, c=colors[df.cluster], figsize=(10,10), s=100);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example Scipy**\n",
    "\n",
    "- Use Scipy's hierarchy for Hierarchical clustering.\n",
    "\n",
    "\n",
    "**Parameters:**\n",
    "\n",
    "```\n",
    "y : ndarray\n",
    "A condensed distance matrix. A condensed distance matrix is a flat array containing the upper triangular of the distance matrix. This is the form that pdist returns. Alternatively, a collection of  observation vectors in  dimensions may be passed as an  by  array. All elements of the condensed distance matrix must be finite, i.e. no NaNs or infs.\n",
    "\n",
    "method : str, optional\n",
    "The linkage algorithm to use. See the Linkage Methods section below for full descriptions.\n",
    "\n",
    "metric : str or function, optional\n",
    "The distance metric to use in the case that y is a collection of observation vectors; ignored otherwise. See the pdist function for a list of valid distance metrics. A custom distance function can also be used.\n",
    "\n",
    "optimal_ordering : bool, optional\n",
    "If True, the linkage matrix will be reordered so that the distance between successive leaves is minimal. This results in a more intuitive tree structure when the data are visualized. defaults to False, because this algorithm can be slow, particularly on large datasets [2]. See also the optimal_leaf_ordering function.\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## found from https://docs.scipy.org/doc/scipy/reference/generated/scipy.cluster.hierarchy.dendrogram.html\n",
    "\n",
    "df = pd.read_csv(\"../../data/iris.csv\")\n",
    "cols = df.columns[:-1]\n",
    "\n",
    "## Collect features\n",
    "X = df[cols]\n",
    "\n",
    "## Scale fatures\n",
    "scaler = StandardScaler()\n",
    "X_scaled = preprocessing.MinMaxScaler().fit_transform(X)\n",
    "\n",
    "## Fit and get labels\n",
    "Z = hierarchy.linkage(X_scaled, 'ward')\n",
    "\n",
    "plt.figure(figsize=(18,8))\n",
    "dn = hierarchy.dendrogram(Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA5wAAAHmCAYAAAAflIFfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nCCFEW5DCKYQQQgghhBCiLfx//L+u/qMZ69EAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11c2862d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "hierarchy.set_link_color_palette(['m', 'c', 'y', 'k'])\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 8))\n",
    "dn1 = hierarchy.dendrogram(Z, ax=axes[0], above_threshold_color='y',\n",
    "                           orientation='top')\n",
    "dn2 = hierarchy.dendrogram(Z, ax=axes[1], above_threshold_color='#bcbddc', orientation='right')\n",
    "hierarchy.set_link_color_palette(None)  # reset to default after use\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"clustering-classification-and-regression\"></a>\n",
    "## Clustering, Classification, and Regression\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use clustering to discover new features, then use those features for either classification or regression.\n",
    "\n",
    "For classification, we could use clusters directly to classify new points.\n",
    "\n",
    "For regression, we could use a dummy variable for the clusters as a variable in our regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "\n",
    "import random\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from scipy.stats import multivariate_normal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a function to plot the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_colors(labels, colors='rgbykcm'):\n",
    "    colored_labels = []\n",
    "    for label in labels:\n",
    "        colored_labels.append(colors[label])\n",
    "    return colored_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create some synthetic data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.4602208402750555, -0.3653877441755106]\n",
      "[-0.5092574553010462, -0.527467813505005]\n",
      "[0.9396193580399139, 1.2906245701439885]\n",
      "[-0.6975501858324442, -1.010785303077577]\n",
      "[0.05966963697329125, 0.6538492198576777]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/scipy/stats/_multivariate.py:660: RuntimeWarning: covariance is not symmetric positive-semidefinite.\n",
      "  out = random_state.multivariate_normal(mean, cov, size)\n"
     ]
    }
   ],
   "source": [
    "dist = multivariate_normal(mean=[0, 0], cov=[[0.5, 0.5],[0,0.1]])\n",
    "\n",
    "for i in range(5):\n",
    "    print(list(dist.rvs()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/scipy/stats/_multivariate.py:660: RuntimeWarning: covariance is not symmetric positive-semidefinite.\n",
      "  out = random_state.multivariate_normal(mean, cov, size)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from scipy.stats import multivariate_normal\n",
    "## Create fake data\n",
    "data = []\n",
    "\n",
    "## Group 1\n",
    "dist = multivariate_normal(mean=[0, 0], cov=[[0.5, 0.5],[0,0.1]])\n",
    "for i in range(150):\n",
    "    data.append(dist.rvs())\n",
    "    \n",
    "## Group 2\n",
    "dist = multivariate_normal(mean=[1, 5], cov=[[0.5, 0.5],[0,0.1]])\n",
    "for i in range(150):\n",
    "    data.append(dist.rvs())\n",
    "    \n",
    "## Group 3\n",
    "dist = multivariate_normal(mean=[2, 10], cov=[[0.5, 0.5],[0,0.1]])\n",
    "for i in range(150):\n",
    "    data.append(dist.rvs())\n",
    "\n",
    "    \n",
    "df = pd.DataFrame(data, columns=[\"x\", \"y\"])\n",
    "df.head()\n",
    "plt.scatter(df['x'], df['y'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.733497</td>\n",
       "      <td>-1.133982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.705112</td>\n",
       "      <td>0.389261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.015329</td>\n",
       "      <td>-0.171915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.144673</td>\n",
       "      <td>1.129187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.124370</td>\n",
       "      <td>0.511046</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          x         y\n",
       "0 -0.733497 -1.133982\n",
       "1  0.705112  0.389261\n",
       "2 -0.015329 -0.171915\n",
       "3  1.144673  1.129187\n",
       "4  1.124370  0.511046"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  1,  1,  1,\n",
       "        1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "        1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "        1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "        1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "        1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "        1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "        1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "        1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "        1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  2,  2,  2,  2,  2,  2,\n",
       "        2,  2, -1,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,\n",
       "        2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,\n",
       "        2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,\n",
       "        2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,\n",
       "        2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,\n",
       "        2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,\n",
       "        2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,\n",
       "        2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,\n",
       "        2,  2,  2,  2,  2,  2,  2,  2])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit a DBSCAN estimator.\n",
    "estimator = DBSCAN(eps=0.8, min_samples=10)\n",
    "X = df[[\"x\", \"y\"]]\n",
    "estimator.fit(X)\n",
    "# Clusters are given in the labels_ attribute.\n",
    "labels = estimator.labels_\n",
    "\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = set_colors(labels)\n",
    "plt.scatter(df['x'], df['y'], c=colors)\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"y\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add cluster labels back to the `DataFrame`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Note that -1 clusters are outliers.\n",
    "df[\"cluster\"] = labels\n",
    "df = pd.concat([df, pd.get_dummies(df['cluster'], prefix=\"cluster\")], axis=1)\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fit a linear model with clusters included."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9911329913575183\n"
     ]
    }
   ],
   "source": [
    "## Instantiate\n",
    "model = LinearRegression()\n",
    "X = df[[\"x\", \"cluster_0\", \"cluster_1\", \"cluster_2\"]]\n",
    "y = df['y']\n",
    "\n",
    "## Fit LR model\n",
    "model.fit(X, y)\n",
    "\n",
    "print((model.score(X, y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = set_colors(labels)\n",
    "plt.scatter(df['x'], df['y'], c=colors)\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"y\")\n",
    "\n",
    "plt.scatter(df[\"x\"], model.predict(X), color='black')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What happens if we don't include the clusters we estimated?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegression()\n",
    "X = df[[\"x\"]]\n",
    "y = df['y']\n",
    "model.fit(X, y)\n",
    "print((model.score(X, y)))\n",
    "\n",
    "colors = set_colors(labels)\n",
    "plt.scatter(df['x'], df['y'], c=colors)\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"y\")\n",
    "\n",
    "plt.scatter(df[\"x\"], model.predict(X), color='black')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"comparing-clustering-algorithms\"></a>\n",
    "## Comparing Clustering Algorithms\n",
    "\n",
    "- K-means\n",
    "  - Finds cluster centers.\n",
    "  - Must choose the number of clusters.\n",
    "  - Assumes clusters are isotropic (not varying in magnitude according to the direction of measurement).\n",
    "- DBSCAN\n",
    "  - Inspects local density to find clusters.\n",
    "  - Better than k-means for anisotropic clusters.\n",
    "  - Capable of finding outliers.\n",
    "- Hierarchical clustering\n",
    "  - Finds clusters by forming groups of groups of groups of points.\n",
    "  - Hierarchical clustering works well for non-spherical clusters.\n",
    "  - May be computationally expensive.\n",
    "  - Guaranteed to converge to the same solution (no random initialization)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"lesson-summary\"></a>\n",
    "## Lesson Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Supervised learning vs. unsupervised learning\n",
    "    - The main difference between the two is whether we use response labels.\n",
    "- K-means, DBSCAN, and hierarchical clustering\n",
    "- Inertia and Silhouette Score\n",
    "- Using clustering along with supervised learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
